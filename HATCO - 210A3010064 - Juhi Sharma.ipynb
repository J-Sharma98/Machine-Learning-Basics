{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4852aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries to import \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.stats as stats\n",
    "import os\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209b41db",
   "metadata": {},
   "source": [
    "-- X1 Delivery speed---amount of time it takes to deliver the product once an\n",
    "order has been confirmed\n",
    "\n",
    "-- X2 Price level---perceived level of price charged by product suppliers\n",
    "\n",
    "-- X3 Price flexibility---perceived willingness of HATCO representatives to\n",
    "negotiate price on all types of purchases\n",
    "\n",
    "-- X4 Manufacturer's image---overall image of the manufacturer/supplier\n",
    "\n",
    "-- X5 Service---overall level of service necessary for maintaining a satisfactory\n",
    "relationship between supplier and purchaser\n",
    "\n",
    "-- X6 Salesforce's image---overall image of the manufacturer's sales force\n",
    "\n",
    "-- X7 Product quality---perceived level of quality of a particular product (e.g.,\n",
    "performance or yield) \n",
    "\n",
    "-- X8 Size of firm---size of the firm relative to others in this market. This\n",
    "variable has two categories: 1=large, and 0=small \n",
    "\n",
    "-- X9 Usage level---how much of the firm's total product is purchased from\n",
    "HATCO, measured on a 100-point percentage scale, ranging from 0 to 100\n",
    "percent\n",
    "\n",
    "-- X10 Satisfaction level---how satisfied the purchaser is with past purchases\n",
    "from HATCO, measured on the same graphic rating scale as the perceptions\n",
    "X1 to X7\n",
    "\n",
    "-- X11 Specification buying---extent to which a particular purchaser evaluates\n",
    "each purchase separately (total value analysis) versus the use of specification\n",
    "buying, which details precisely the product characteristics desired. This\n",
    "variable has two categories: 1=employs total value analysis approach,\n",
    "evaluating each purchase separately, and 0=use of specification buying\n",
    "\n",
    "-- X12 Structure of procurement---method of procuring/purchasing products\n",
    "within a particular company. This variable has two categories: 1=centralized\n",
    "procurement, and 0=decentralized procurement\n",
    "\n",
    "-- X13 Type of industry---industry classification in which a product purchaser\n",
    "belongs. This variable has two categories: 1=industry A classification, and\n",
    "0=other industries\n",
    "\n",
    "-- X14 Type of buying situation---type of situation facing the purchaser. This\n",
    "variable has three categories: 1=new task, 2=modified rebuy, and 3=straight\n",
    "rebuy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280847dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to turn off scientific notation\n",
    "pd.options.display.float_format = '{:.2f}'.format # to have formating of output to two decimal value \n",
    "# pd.set_option(\"display.precision\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446dac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'D:\\BML Munjal University\\Module 6\\Predictive Analytics')\n",
    "# reading data\n",
    "data = pd.read_excel(\"hatco.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580df3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b4fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46694a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948d411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbac6ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "average = [['X1', data['X1'].mean()], ['X2', data['X2'].mean()],['X3', data['X3'].mean()],\n",
    "       ['X4', data['X4'].mean()], ['X5', data['X5'].mean()],['X6', data['X6'].mean()],\n",
    "       ['X7', data['X7'].mean()]]\n",
    "  \n",
    "# Create the pandas DataFrame\n",
    "average_data = pd.DataFrame(average, columns=['Feature', 'Average'])\n",
    "average_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f888de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,7))\n",
    "sns.barplot(data=average_data, x=\"Feature\", y=\"Average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0d1f92",
   "metadata": {},
   "source": [
    "We can see that the highest average is of X3, which means the perceived wilingness of HATCO representatives to negotiate price on all types of purchases is highest. The perceived level of quality of a particular product is nearly excellent. The perceived level of price charged by the product suppliers is very poor. It means that the suppliers think that the price charged by HATCO for the products are higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f556d448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let 40% be the threshold for usage level\n",
    "\n",
    "high_usage = data.loc[data['X9']>=40]\n",
    "low_usage = data.loc[data['X9']<40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c53bc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(low_usage)\n",
    "#len(high_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d273a549",
   "metadata": {},
   "outputs": [],
   "source": [
    "usage = [['High Usage',73],['Low Usage',27]]\n",
    "usage = pd.DataFrame(usage,columns=['Usage', 'Count'])\n",
    "usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3969816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,7))\n",
    "sns.barplot(data=usage, x=\"Usage\", y=\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00d0d16",
   "metadata": {},
   "source": [
    "There are only a few respondents have low purchase from HATCO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc74dc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num = data.select_dtypes(exclude = 'object')\n",
    "data_cat = data.select_dtypes(include = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7389a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9c56b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm = data_num.copy()\n",
    "  \n",
    "# apply normalization techniques\n",
    "for column in data_norm.columns:\n",
    "    data_norm[column] = data_norm[column]  / data_norm[column].abs().max()\n",
    "      \n",
    "# view normalized data\n",
    "display(data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab78462",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.boxplot(data=data_norm.drop(data_norm.columns[[0]], axis=1), orient=\"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e722f62",
   "metadata": {},
   "source": [
    "We can see that there are only a few outliers in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f97712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = np.percentile(data_norm['X5'], 25, interpolation = 'midpoint') \n",
    "Q2 = np.percentile(data_norm['X5'], 50, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(data_norm['X5'], 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "low_lim1 = Q1 - 1.5 * IQR\n",
    "up_lim1 = Q3 + 1.5 * IQR\n",
    "print('low_limit is', low_lim1)\n",
    "print('up_limit is', up_lim1)\n",
    "outlier1 =[]\n",
    "for x in data_norm['X5']:\n",
    "    if ((x> up_lim1) or (x<low_lim1)):\n",
    "         outlier1.append(x)\n",
    "print(' Number of outlier in the dataset is', len(outlier1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e786cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = np.percentile(data_norm['X4'], 25, interpolation = 'midpoint') \n",
    "Q2 = np.percentile(data_norm['X4'], 50, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(data_norm['X4'], 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "low_lim2 = Q1 - 1.5 * IQR\n",
    "up_lim2 = Q3 + 1.5 * IQR\n",
    "print('low_limit is', low_lim2)\n",
    "print('up_limit is', up_lim2)\n",
    "outlier2 =[]\n",
    "for x in data_norm['X4']:\n",
    "    if ((x> up_lim2) or (x<low_lim2)):\n",
    "         outlier2.append(x)\n",
    "print(' Number of outlier in the dataset is', len(outlier2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c56280",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = np.percentile(data_norm['X6'], 25, interpolation = 'midpoint') \n",
    "Q2 = np.percentile(data_norm['X6'], 50, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(data_norm['X6'], 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "low_lim3 = Q1 - 1.5 * IQR\n",
    "up_lim3 = Q3 + 1.5 * IQR\n",
    "print('low_limit is', low_lim3)\n",
    "print('up_limit is', up_lim3)\n",
    "outlier3 =[]\n",
    "for x in data_norm['X6']:\n",
    "    if ((x> up_lim3) or (x<low_lim3)):\n",
    "         outlier3.append(x)\n",
    "print(' Number of outlier in the dataset is', len(outlier3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45319620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capping the outliers\n",
    "\n",
    "data_norm[\"X6\"] = np.where(data_norm[\"X6\"]> up_lim3, up_lim3,\n",
    "                        np.where(data_norm[\"X6\"]< low_lim3, low_lim3,\n",
    "                        data_norm[\"X6\"]))\n",
    "data_norm[\"X5\"] = np.where(data_norm[\"X5\"]> up_lim1, up_lim1,\n",
    "                        np.where(data_norm[\"X5\"]< low_lim1, low_lim1,\n",
    "                        data_norm[\"X5\"]))\n",
    "data_norm[\"X4\"] = np.where(data_norm[\"X4\"]> up_lim2, up_lim2,\n",
    "                        np.where(data_norm[\"X4\"]< low_lim2, low_lim2,\n",
    "                        data_norm[\"X4\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3fce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.boxplot(data=data_norm.drop(data_norm.columns[[0]], axis=1), orient=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fef54e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist(variable):\n",
    "    sns.histplot(data=data_norm, x=variable, kde=True)\n",
    "\n",
    "def box(var):\n",
    "    sns.boxplot(x=data_norm[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9587e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "box(\"X1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4317dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(\"X1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca988a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(\"X2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c930747",
   "metadata": {},
   "outputs": [],
   "source": [
    "box(\"X2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f465b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(\"X3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37b44ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "box(\"X3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b796cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(\"X4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3cb5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "box(\"X4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4bd276",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(\"X5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac034db",
   "metadata": {},
   "outputs": [],
   "source": [
    "box(\"X5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea98b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(\"X6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc65b0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "box(\"X6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0c4324",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(\"X7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eee65fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "box(\"X7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc376d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(\"X9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5057404",
   "metadata": {},
   "outputs": [],
   "source": [
    "box(\"X9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ef9070",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(\"X10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d2f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "box(\"X10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46302a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(data_norm.corr(), linewidths=0.5, annot=True, fmt=\".2f\", cmap = 'viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc12373",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(15,10)\n",
    "data_num.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410beea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3d6e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_sat = data.loc[data['X10']<=5]\n",
    "high_sat = data.loc[data['X10']>5]\n",
    "print(\"low \",len(low_sat))\n",
    "print(\"high \",len(high_sat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11a96c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us look at the purchasers who have low satisfaction with the past purchases.\n",
    "\n",
    "low_sat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b93e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.boxplot(data=low_sat.drop(low_sat.columns[[0]], axis=1), orient=\"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e0225b",
   "metadata": {},
   "source": [
    "One of the respondents receieved very low customer service (X5) due to which he is low satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc19d530",
   "metadata": {},
   "source": [
    "Even though the delivery time of a respondent was very low (X1), still he is not satisfied. The company should probe more on this respondent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd726f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data['X8'], [data['X11']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd3411a",
   "metadata": {},
   "source": [
    "There are no small firms that use specification buying. There are no large firm which employ total value analysis approach. There are 60 small firms which employ total value analysis approach, there are 40 large firms which employ specification buying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3626449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data['X8'], [data['X12']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f581b02e",
   "metadata": {},
   "source": [
    "No large firms have decentralized procurement structure. 50 small firms have decentralized procurement structure. Only 10 small firms have centralized procurement structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1cc8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data['X8'], [data['X13']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd2fe94",
   "metadata": {},
   "source": [
    "Equal number of small and large firms belong to industry A classification and other classification of industries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156631bf",
   "metadata": {},
   "source": [
    "Problem Statment 1 - To predict the usage level of the firms\n",
    "Problem Statment 2 - To predict the type of buying situation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da7e4db",
   "metadata": {},
   "source": [
    "# To predict the usage level of the firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742a2171",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04491d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data_norm,hue ='X13')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fe3250",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f7638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = data_norm.drop(data_norm.columns[[9]], axis=1)\n",
    "y1 = data_norm['X9']\n",
    "x1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca18055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Split the data into x_train and x_test, y_train and y_test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x1_train, x1_test, y1_train, y1_test = train_test_split(x1, y1, test_size=0.2, random_state=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c48df46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x1_train.shape)\n",
    "print(x1_test.shape)\n",
    "print(y1_train.shape)\n",
    "print(y1_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dddb76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5: Train the model using x_train and y_train\n",
    "import statsmodels.api as sm\n",
    "lin_reg_model_1 = sm.OLS(y1_train, x1_train).fit()\n",
    "lin_reg_model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bf38cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 6: Pass x_test to the model to predict y.\n",
    "predictions_model_1 = lin_reg_model_1.predict(x1_test)\n",
    "predictions_model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c0942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_test\n",
    "#This is not close to the historical y. So now you do RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713670b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y1_test, predictions_model_1)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2af380",
   "metadata": {},
   "source": [
    "# Removing variables with p value less than 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9cb7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c23b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removed only ID and Manufacturer's image. Others seem to be significant.\n",
    "x2 = data_norm.drop(data_norm.columns[[9,0,4]], axis=1)\n",
    "y2 = data_norm['X9']\n",
    "x2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87002afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Split the data into x_train and x_test, y_train and y_test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(x2, y2, test_size=0.2, random_state=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e5384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x2_train.shape)\n",
    "print(x2_test.shape)\n",
    "print(y2_train.shape)\n",
    "print(y2_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f9af9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "lin_reg_model_2 = sm.OLS(y2_train, x2_train).fit()\n",
    "lin_reg_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0ec039",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_model_2 = lin_reg_model_2.predict(x2_test)\n",
    "predictions_model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a517b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y2_test, predictions_model_2)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd84f24",
   "metadata": {},
   "source": [
    "# VIF treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d387cf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(x1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3598d8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5a5e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "  \n",
    "# the independent variables set\n",
    "X1 = X[['ID', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X10',\n",
    "       'X11', 'X12', 'X13', 'X14']]\n",
    "  \n",
    "# VIF dataframe\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X1.columns\n",
    "  \n",
    "# calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X1.values, i)\n",
    "                          for i in range(len(X1.columns))]\n",
    "  \n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2667f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we remove service (X5)\n",
    "  \n",
    "# the independent variables set\n",
    "X2 = X1[['X1', 'X2', 'X3', 'X4', 'X11', 'X6', 'X7', 'X8',\n",
    "         'X10','X12', 'X13', 'X14']]\n",
    "  \n",
    "# VIF dataframe\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X2.columns\n",
    "  \n",
    "# calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X2.values, i)\n",
    "                          for i in range(len(X2.columns))]\n",
    "  \n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4e7d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we remove structure of procurement (X12)\n",
    "\n",
    "# the independent variables set\n",
    "X3 = X2[['X1', 'X2', 'X3', 'X4', 'X6','X11', 'X7', 'X8',\n",
    "         'X10','X13','X14']]\n",
    "  \n",
    "# VIF dataframe\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X3.columns\n",
    "  \n",
    "# calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X3.values, i)\n",
    "                          for i in range(len(X3.columns))]\n",
    "  \n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a55f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ec4c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3= pd.concat([X3,data_norm['X9']], axis = 1)\n",
    "X3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7571c9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "lm = ols(\"X9 ~ X1+X2+X3+X4+X6+X11+X7+X8+X10+X13+X14\", data=X3).fit()\n",
    "print(lm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cfe053",
   "metadata": {},
   "source": [
    "Performance decreased."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ecce0e",
   "metadata": {},
   "source": [
    "# Using cook's distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e803f95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import CooksDistance\n",
    "from yellowbrick.datasets import load_concrete\n",
    "\n",
    "# Load the regression dataset\n",
    "x1, y1 = load_concrete()\n",
    "\n",
    "# Instantiate and fit the visualizer\n",
    "visualizer = CooksDistance()\n",
    "visualizer.fit(x1, y1)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055986cf",
   "metadata": {},
   "source": [
    "The presence of so many highly influential points suggests that linear regression may not be suitable for this dataset. One or more of the four assumptions behind linear regression might be being violated; namely one of: independence of observations, linearity of response, normality of residuals, or homogeneity of variance (“homoscedasticity”)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c692cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from yellowbrick.regressor import ResidualsPlot\n",
    "\n",
    "# Instantiate and fit the visualizer\n",
    "model3 = LinearRegression()\n",
    "visualizer_residuals = ResidualsPlot(model3)\n",
    "visualizer_residuals.fit(x1, y1)\n",
    "visualizer_residuals.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf9f449",
   "metadata": {},
   "source": [
    "The residuals appear to be normally distributed around 0, satisfying the linearity and normality conditions. However, they do skew slightly positive for larger predicted values, and also appear to increase in magnitude as the predicted value increases, suggesting a violation of the homoscedasticity condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3e8c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35de743",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = ols(\"X9 ~ X1+X2+X3+X4+X5+X6+X7+X8+X11+X10+X12+X13+X14 \", data=data_norm).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d275d43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print regression results\n",
    "print(lm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b682a282",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sm.graphics.influence_plot(lm, criterion=\"cooks\")\n",
    "fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66aa9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain Cook's distance \n",
    "lm_cooksd = lm.get_influence().cooks_distance[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c32743",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(data_norm[\"X1\"])\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4b95dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate critical d\n",
    "critical_d = 4/n\n",
    "print('Critical Cooks distance:', critical_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0eb5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_d = lm_cooksd > critical_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c35cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_norm.index[out_d], \"\\n\", \n",
    "    lm_cooksd[out_d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b9f594",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm.loc[[21, 29, 52, 54, 81, 99],]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142bfac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data_norm.drop([21,29,52,54,81,99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30cfab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8c159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x4 = new_data.drop('X9',axis=1)\n",
    "y4 = new_data['X9']\n",
    "x4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac4b49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Split the data into x_train and x_test, y_train and y_test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x4_train, x4_test, y4_train, y4_test = train_test_split(x4, y4, test_size=0.2, random_state=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68df5a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x4_train.shape)\n",
    "print(x4_test.shape)\n",
    "print(y4_train.shape)\n",
    "print(y4_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d448cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "lin_reg_model_4 = sm.OLS(y4_train, x4_train).fit()\n",
    "lin_reg_model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da943287",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_model_4 = lin_reg_model_4.predict(x4_test)\n",
    "predictions_model_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d579774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y4_test, predictions_model_4)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392e7f01",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb122337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing or loading the dataset\n",
    "dataset = pd.read_excel('HATCO.xlsx')\n",
    "  \n",
    "# distributing the dataset into two components X and Y\n",
    "X = dataset.iloc[:, [1,2,3,4,5,6,7,8,9,10,11,12,13,14]].values\n",
    "y = dataset.iloc[:, 8].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29ca8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the X and Y into the\n",
    "# Training set and Testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c363458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing preprocessing part\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e5bbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying PCA function on training\n",
    "# and testing set of X component\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 2)\n",
    "\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "explained_variance = pca.explained_variance_ratio_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a8192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bddbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Logistic Regression To the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39101e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test set result using\n",
    "# predict function under LogisticRegression\n",
    "y_pred = classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a982451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making confusion matrix between\n",
    "# test set of Y and predicted value.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef6c4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "s1 = sns.heatmap(cm ,annot=True ,fmt='d')\n",
    "s1.set(xlabel='Predicted', ylabel='Actual')\n",
    "print(\"Model accuracy for model 1:\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670ebce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the training set\n",
    "# result through scatter plot\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "X_set, y_set = X_train, y_train\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1,\n",
    "\t\t\t\t\tstop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "\t\t\t\t\tnp.arange(start = X_set[:, 1].min() - 1,\n",
    "\t\t\t\t\tstop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(),\n",
    "\t\t\tX2.ravel()]).T).reshape(X1.shape), alpha = 0.75,\n",
    "\t\t\tcmap = ListedColormap(('yellow', 'white', 'aquamarine')))\n",
    "\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "\tplt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "\t\t\t\tc = ListedColormap(('red', 'green', 'blue'))(i), label = j)\n",
    "\n",
    "plt.title('Logistic Regression (Training set)')\n",
    "plt.xlabel('PC1') # for Xlabel\n",
    "plt.ylabel('PC2') # for Ylabel\n",
    "plt.legend() # to show legend\n",
    "\n",
    "# show scatter plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975ad0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the Test set results through scatter plot\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "X_set, y_set = X_test, y_test\n",
    "\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1,\n",
    "\t\t\t\t\tstop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "\t\t\t\t\tnp.arange(start = X_set[:, 1].min() - 1,\n",
    "\t\t\t\t\tstop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "\n",
    "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(),\n",
    "\t\t\tX2.ravel()]).T).reshape(X1.shape), alpha = 0.75,\n",
    "\t\t\tcmap = ListedColormap(('yellow', 'white', 'aquamarine')))\n",
    "\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "\tplt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "\t\t\t\tc = ListedColormap(('red', 'green', 'blue'))(i), label = j)\n",
    "\n",
    "# title for scatter plot\n",
    "plt.title('Logistic Regression (Test set)')\n",
    "plt.xlabel('PC1') # for Xlabel\n",
    "plt.ylabel('PC2') # for Ylabel\n",
    "plt.legend()\n",
    "\n",
    "# show scatter plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a418e5",
   "metadata": {},
   "source": [
    "# Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8860de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ecc5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, init=\"k-means++\",random_state=0)\n",
    "kmeans.fit(data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da24b837",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89122b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "wcss = []\n",
    "for k in range(2,11):\n",
    "    kmeans = KMeans(n_clusters=k, init=\"k-means++\",random_state=42)\n",
    "    kmeans.fit(data_norm)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "plt.figure(figsize=(12,6))    \n",
    "plt.grid()\n",
    "plt.plot(range(2,11),wcss, linewidth=2, color=\"red\", marker =\"8\")\n",
    "plt.xlabel(\"K Value\")\n",
    "plt.xticks(np.arange(1,11,1))\n",
    "plt.ylabel(\"WCSS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77150b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=5,random_state = 42)\n",
    "clusters = km.fit_predict(data_norm)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326f6466",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm[\"label\"] = clusters\n",
    "data_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac0a22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(data_norm.X1[data_norm.label == 0], data_norm[\"X2\"][data_norm.label == 0], data_norm[\"X3\"][data_norm.label == 0], c='blue', s=60)\n",
    "ax.scatter(data_norm.X1[data_norm.label == 1], data_norm[\"X2\"][data_norm.label == 1], data_norm[\"X3\"][data_norm.label == 1], c='red', s=60)\n",
    "ax.scatter(data_norm.X1[data_norm.label == 2], data_norm[\"X2\"][data_norm.label == 2], data_norm[\"X3\"][data_norm.label == 2], c='green', s=60)\n",
    "ax.scatter(data_norm.X1[data_norm.label == 3], data_norm[\"X2\"][data_norm.label == 3], data_norm[\"X3\"][data_norm.label == 3], c='orange', s=60)\n",
    "ax.scatter(data_norm.X1[data_norm.label == 4], data_norm[\"X2\"][data_norm.label == 4], data_norm[\"X3\"][data_norm.label == 4], c='purple', s=60)\n",
    "ax.view_init(30, 185)\n",
    "plt.xlabel(\"Delivery Speed\")\n",
    "plt.ylabel(\"Price Level\")\n",
    "ax.set_zlabel('Price Flexibility')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba3ba22",
   "metadata": {},
   "source": [
    "Calculate centroids, and interpret the centroids of each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73929fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm.groupby(\"label\")['X1'].mean().plot.bar() # Delivery speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8b85b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm.groupby(\"label\")['X2'].mean().plot.bar() #Price level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b839f295",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm.groupby(\"label\")['X3'].mean().plot.bar() # Price flexibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be448461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 6 clusters\n",
    "km = KMeans(n_clusters=6,random_state = 42)\n",
    "clusters = km.fit_predict(data_norm)\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fff8817",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm[\"label\"] = clusters\n",
    "data_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec81a381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(data_norm.X1[data_norm.label == 0], data_norm[\"X2\"][data_norm.label == 0], data_norm[\"X3\"][data_norm.label == 0], c='blue', s=60)\n",
    "ax.scatter(data_norm.X1[data_norm.label == 1], data_norm[\"X2\"][data_norm.label == 1], data_norm[\"X3\"][data_norm.label == 1], c='red', s=60)\n",
    "ax.scatter(data_norm.X1[data_norm.label == 2], data_norm[\"X2\"][data_norm.label == 2], data_norm[\"X3\"][data_norm.label == 2], c='green', s=60)\n",
    "ax.scatter(data_norm.X1[data_norm.label == 3], data_norm[\"X2\"][data_norm.label == 3], data_norm[\"X3\"][data_norm.label == 3], c='orange', s=60)\n",
    "ax.scatter(data_norm.X1[data_norm.label == 4], data_norm[\"X2\"][data_norm.label == 4], data_norm[\"X3\"][data_norm.label == 4], c='purple', s=60)\n",
    "ax.scatter(data_norm.X1[data_norm.label == 5], data_norm[\"X2\"][data_norm.label == 5], data_norm[\"X3\"][data_norm.label == 5], c='black', s=60)\n",
    "ax.view_init(30, 185)\n",
    "plt.xlabel(\"Delivery Speed\")\n",
    "plt.ylabel(\"Price Level\")\n",
    "ax.set_zlabel('Price Flexibility')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7901975",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm.groupby(\"label\")['X1'].mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4b7d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm.groupby(\"label\")['X2'].mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f6d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm.groupby(\"label\")['X3'].mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a77d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b965a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster\n",
    "dd = data_norm.loc[:,[\"X1\",\"X2\",\"X3\",\"X4\",\"X5\",\"X6\",\"X7\",\"X8\"]]\n",
    "dd1 = dd.drop(\"X8\",axis = 1)\n",
    "k_means = cluster.KMeans(n_clusters=2, max_iter=50, random_state=1)\n",
    "k_means.fit(dd1) \n",
    "labels = k_means.labels_\n",
    "pd.DataFrame(labels, index=dd.X8, columns=['Cluster ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18965735",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = k_means.cluster_centers_\n",
    "pd.DataFrame(centroids,columns=dd1.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2ada64",
   "metadata": {},
   "source": [
    "Those respondents who have a perception of/higher ratings for:\n",
    "High:\n",
    "Delivery speed\n",
    "Price flexibility\n",
    "Manufacturer's image\n",
    "Product quality\n",
    "Service\n",
    "Low:\n",
    "Price level\n",
    "Salesforce image\n",
    "are small firms.\n",
    "\n",
    "Those respondents who have a perception of:\n",
    "High:\n",
    "Price level\n",
    "Manufacturer's image\n",
    "Price flexibility\n",
    "Service\n",
    "Salesforce image\n",
    "Product quality\n",
    "Low:\n",
    "Delivery speed\n",
    "are large firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7823921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "numClusters = [1,2,3,4,5,6]\n",
    "SSE = []\n",
    "for k in numClusters:\n",
    "    k_means = cluster.KMeans(n_clusters=k)\n",
    "    k_means.fit(data)\n",
    "    SSE.append(k_means.inertia_)\n",
    "\n",
    "plt.plot(numClusters, SSE)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('SSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1e0383",
   "metadata": {},
   "source": [
    "# CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac560950",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f2b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removed only ID and Manufacturer's image. Others seem to be significant.\n",
    "x5 = data_norm.drop(data_norm.columns[[9,0]], axis=1)\n",
    "y5 = data_norm['X9']\n",
    "x5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa6ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x5_train, x5_test, y5_train, y5_test = train_test_split(x5, y5, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78854c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24892ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a regressor object\n",
    "regressor = DecisionTreeRegressor(random_state = 0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e37038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the regressor with X and Y data\n",
    "regressor = regressor.fit(x5_train, y5_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b796753",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(x5_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b75d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse3 = mean_squared_error(y5_test, y_pred)\n",
    "rmse3 = np.sqrt(mse3)\n",
    "print(\"RMSE:\",rmse3)\n",
    "print(\"MSE:\",mse3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b34976d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0a8168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eb0b55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
